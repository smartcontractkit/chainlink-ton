name: Temp MyLocalTON Test - Prebuilt Images

on:
  push:
    branches:
      - feature/mylocalton
  pull_request:

jobs:
  test-localnet:
    name: Testing MyLocalTON
    runs-on: ubuntu-latest
    steps:
      - name: Check out code
        uses: actions/checkout@0ad4b8fadaa221de15dcec353f45205ec38ea70b # v4.1.4

      - name: Install Nix
        uses: cachix/install-nix-action@02a151ada4993995686f9ed4f1be7cfbb229e56f # v31
        with:
          nix_path: nixpkgs=channel:nixos-unstable

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v2

      - name: Login to GitHub Container Registry
        uses: docker/login-action@v2
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Cache Docker volumes
        id: cache-volumes
        uses: actions/cache@v4
        with:
          path: ~/.ton-volumes
          key: ${{ runner.os }}-ton-volumes-${{ hashFiles('docker-compose.yaml') }}
          restore-keys: |
            ${{ runner.os }}-ton-volumes-

      # Prepare cache directory
      - name: Prepare cache directory and set env vars
        run: |
          mkdir -p ~/.ton-volumes

          # Set up bind mounts if we have cached volumes
          if [ "${{ steps.cache-volumes.outputs.cache-hit }}" == "true" ]; then
            echo "Using cached volumes from previous run"
            
            # Create volume subdirectories if they don't exist

            mkdir -p ~/.ton-volumes/{shared-data,ton-db,postgres-data,index-workdir}
            
            # Set env vars for volume bind mounts (to both current shell and GITHUB_ENV)
            echo "VOLUME_DRIVER=local" >> $GITHUB_ENV
            echo "SHARED_DATA_O_OPT=bind" >> $GITHUB_ENV
            echo "SHARED_DATA_TYPE_OPT=none" >> $GITHUB_ENV
            echo "SHARED_DATA_DEVICE_OPT=$HOME/.ton-volumes/shared-data" >> $GITHUB_ENV

            echo "TON_DB_O_OPT=bind" >> $GITHUB_ENV
            echo "TON_DB_TYPE_OPT=none" >> $GITHUB_ENV
            echo "TON_DB_DEVICE_OPT=$HOME/.ton-volumes/ton-db" >> $GITHUB_ENV

            echo "POSTGRES_DATA_O_OPT=bind" >> $GITHUB_ENV
            echo "POSTGRES_DATA_TYPE_OPT=none" >> $GITHUB_ENV
            echo "POSTGRES_DATA_DEVICE_OPT=$HOME/.ton-volumes/postgres-data" >> $GITHUB_ENV

            echo "INDEX_WORKDIR_O_OPT=bind" >> $GITHUB_ENV
            echo "INDEX_WORKDIR_TYPE_OPT=none" >> $GITHUB_ENV
            echo "INDEX_WORKDIR_DEVICE_OPT=$HOME/.ton-volumes/index-workdir" >> $GITHUB_ENV
            
            # Also set COMPOSE_PROJECT_NAME to ensure consistent volume naming
            echo "COMPOSE_PROJECT_NAME=mylocalton" >> $GITHUB_ENV
            export COMPOSE_PROJECT_NAME=mylocalton
          else
            echo "First run - will use default volumes and cache afterward"
          fi

      # Pull and tag images
      - name: Pull and tag images from GitHub Container Registry
        run: |
          TARGET_REGISTRY="ghcr.io/${{ github.repository }}"
          
          IMAGES=(
            "ghcr.io/neodix42/mylocalton-docker:latest" 
            "ghcr.io/neodix42/ton-http-api:latest"
            "ghcr.io/neodix42/mylocalton-docker-faucet:latest"
            "redis:latest"
            "postgres:17"
            "toncenter/ton-indexer-classifier:v1.2.0-test"
            "toncenter/ton-indexer-api:v1.2.0-test"
            "toncenter/ton-indexer-worker:v1.2.0-test"
          )

          SHOULD_PUSH=true
          
          # Create a temporary directory for configs
          mkdir -p /tmp/image_configs
          
          # Start parallel processing
          echo "Starting parallel image processing"
          pids=()
          
          for IMG in "${IMAGES[@]}"; do
            # Start a subshell for parallel processing
            (
              # Extract image name and tag
              IMG_NAME=$(echo $IMG | cut -d: -f1 | sed 's|.*/||')
              IMG_TAG=$(echo $IMG | cut -d: -f2)

              TARGET_IMG="${TARGET_REGISTRY}/mylocalton-${IMG_NAME}:${IMG_TAG}"
              
              if docker manifest inspect ${TARGET_IMG} &>/dev/null; then
                echo "${TARGET_IMG} already exists in registry, using it"
                docker pull ${TARGET_IMG}
              else
                echo "${TARGET_IMG} not found, pulling from source"
                docker pull ${IMG}
                docker tag ${IMG} ${TARGET_IMG}
                
                if [[ "$SHOULD_PUSH" == "true" ]]; then
                  echo "Pushing ${TARGET_IMG} to registry for future runs"
                  echo '{"visibility":"private"}' > /tmp/image_configs/config_${IMG_NAME}.json
                  curl -X PUT -H "Authorization: Bearer ${{ secrets.GITHUB_TOKEN }}" \
                    -H "Content-Type: application/json" \
                    --data @/tmp/image_configs/config_${IMG_NAME}.json \
                    "https://api.github.com/user/packages/container/${TARGET_IMG/ghcr.io\/}"
                  
                  # Push the image
                  docker push ${TARGET_IMG}
                fi
              fi
              
              docker tag ${TARGET_IMG} ${IMG}
              echo "âœ“ Completed processing ${IMG_NAME}:${IMG_TAG}"
            ) &
            
            # Store the process ID
            pids+=($!)
          done
          
          # Wait for all parallel processes to complete
          echo "Waiting for all image processes to complete..."
          for pid in "${pids[@]}"; do
            wait $pid
          done
          
          echo "All images processed in parallel"
          
          # Clean up
          rm -rf /tmp/image_configs
          
          # Show the result
          docker images
      
      # Start TON network and measure startup time
      - name: Start TON Local Network
        id: ton-startup
        run: |
          chmod +x scripts/localnet-up.sh
          scripts/localnet-up.sh
          
          # If this is the first run, copy volume data for future cache
          if [ "${{ steps.cache-volumes.outputs.cache-hit }}" != "true" ]; then
            echo "Caching volumes for future runs"
            mkdir -p ~/.ton-volumes/{shared-data,ton-db,postgres-data,index-workdir}
            
            # Copy container data directly
            docker cp genesis:/usr/share/data/. ~/.ton-volumes/shared-data/
            docker cp genesis:/var/ton-work/db/. ~/.ton-volumes/ton-db/
            docker cp index-postgres:/var/lib/postgresql/data/. ~/.ton-volumes/postgres-data/
            docker cp index-worker:/workdir/. ~/.ton-volumes/index-workdir/
            
            # Set permissions
            chmod -R 777 ~/.ton-volumes
          fi